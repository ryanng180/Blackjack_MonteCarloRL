<h1>CNY Blackjack with Monte Carlo Reinforcement Learning</h1>
<h2>SDSC4026 Sys modelling and Simulation</h2>

<ul>For my exchange program at CITYUHK, I wanted to try my hand at creating a General Golf Course Simulation Tool to Keep Delays Down and Throughput Up. But my groupmates thought it was too complex, it was fair becuase they were new to coding projects and I was also very much unsure of the math behind this really intriguing project. Will be adding this to my list of crazy project ideas</ul>
<ul>redefining the blackjack problem, I figured that this topics will be very popular and hence we settled on (CNY) Chinese New Year's Blackjack, a refreshing take from the usual casino styled Blackjack</ul>
<ul>Blackjack was the perfect topic because it allowed us to abstract the problem as we like, the different context for blackjack games allows for different levels for abstraction. We could dictate the level of difficuly whenever we liked. We could control the difficulty of the coding workload for them while I could challenge myself as I saw fit.</ul>
<ul>Reinterpreting the game of Blackjack by contextualising it to the CNY version at home really gave us the most freedom to explore the gamut of strategies across various levels of modelling and simulation techniques</ul>
<ul>Having done Monte Carlo Simulation on a basic stock portfolio, it was the perfect time for me to try my hand at Monte Carlo Reinforcement Learning for the Blackjack Project.</ul>

Under the moniker of Player Profile 6, I explored 4 Monte Carlo Reinforcement Methods: 
<ol>1. Monte Carlo First Visit</ol>
<ol>2. Monte Carlo Every Visit</ol>
<ol>3. Monte Carlo On Policy</ol>
<ol>4. Monte Carlo Off Policy</ol>

<h2>Resources</h2

<h2>Challenges</h2>

<h2>Reflections</h2>

<h2>Improvements</h2>
Try Temporal Difference Learning, or a hybrid model 
